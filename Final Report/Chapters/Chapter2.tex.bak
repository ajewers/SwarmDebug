% Chapter 2

\chapter[Literature Review]{Literature Review} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

\section{Overview}
This section presents a review of some of the literature from the field of swarm robotics, including some general summaries of the field's fundamentals, as well as a number of specific pieces of research with particular relevance to this project. It also presents a number of pieces of research from other, related areas, such as human-robot interaction and robotics-focused augmented reality research. The results of this literature survey informed the project direction significantly, and formed the basis for many of the design and implementation decisions made later on. It is also presented with the aim of providing the reader with the base of knowledge required to better understand the project. The literature covered in this section can be separated into several broad topics, each informing a different element of the project work.

Firstly an understanding of the fundamental concepts of Swarm Robotics, and to a lesser extent Swarm Intelligence, was deemed key to producing an application that is useful in practice, and will help a reader to better understand the purpose and aims of the project. An overview of the core concepts as well as some key publications are presented in Section \ref{GeneralSwarmRobotics}. A deep understanding of the technical details of specific swarm systems, such as specific behavioural algorithms or implementation details, is not a priority for understanding this project, as the application aims to be more broadly applicable to a wide range of swarm systems. Emphasis was instead placed on understanding the general classification of swarm robotic systems, relevant problem domains, and recurring concepts, so that the software might better serve researchers in the field.

This project focuses on a piece of software which forms an interface between a human operator and a robot swarm. A relevant area of research is therefore Human-Swarm Interaction (HSI). Research in this area focuses on the different ways in which humans and robot swarms can interact, the different roles humans take whilst interacting with robot swarms, and the best practices for facilitating this interaction given different aims, and different types of user (developer, researcher, end user, etc.). The two key challenges of HSI are control - how best to allow a human operator to direct the behaviour of a decentralised swarm - and monitoring - how to retrieve data from a swarm and present it in a useful, human readable manner. This project focuses on the latter problem. An overview of the relevant Human-Swarm Interaction literature is presented in Section \ref{HumanSwarmInteraction}.

As previously explained, augmented reality technologies have been identified as a potentially powerful tool for facilitating human-robot interaction and communication. Section \ref{AugmentedReality} reviews a number of pieces of research relating to the use of AR technologies in conjunction with robotic systems.

A number of pieces of research exist which investigate different ways to monitor and debug single robot and multi-robot systems, using a range of the technologies and concepts discussed previously, sharing common ground with this project. These works are summarised and reviewed in section \ref{SimilarWork}, with a specific focus on other systems applying graphical, AR-style techniques to a debugging context.

%----------------------------------------------------------------------------------------

\section{Swarm Intelligence and Swarm Robotics} \label{GeneralSwarmRobotics}
Sahin \cite{Sahin:2004} presents a summary of the key concepts of swarm robotics, and attempts to offer a coherent description of the topic. He notes that a key difference from other multi-robot systems is the lack of centralised control, and the idea that desired behaviour should emerge from simple local interactions between robots, and between the robots and their environment. He also notes some of the key motivators behind Swarm Robotics research, stating that a swarm robotics system would ideally have ``\textit{robustness}'', ``\textit{flexibility}'' and ``\textit{scalability}'' \cite{Sahin:2004}. Robustness refers to the swarm's ability to continue to function should one or more individual swarm members suffer a failure of some kind. Flexibility refers to the swarm's ability to adapt to changes in the environment without the need for re-programming. Scalability describes the idea that a swarm should be functional at a range of sizes, and that ideally the number of robots in the swarm could be increased or decreased depending on the demands of the task. Sahin \cite{Sahin:2004} goes on to describe several classes of application where Swarm Robotics systems might be well suited. Tasks that cover a region could benefit from a swarm's ability to distribute physically in a space according to need. Dangerous tasks could benefit from the relative dispensability of individual robots in the swarm; should one be damaged or destroyed the swarm could continue to function, and it would be less costly that the loss of a single, complex, expensive robot. Tasks requiring scalability are good candidates, as discussed before, and tasks that require redundancy are also highlighted, as swarm systems should have the ability to degrade gracefully, rather than suffering a single catastrophic failure. Through this generalisation of the application areass, insight can be gained into the kinds of work swarm robotics researchers are likely to be doing, and this should inform the design of the application. This paper \cite{Sahin:2004} provides a coherent, succinct overview of the field, and although it is now over a decade old the concepts covered remain relevant.

%The paper also contains a wealth of further reading, including papers on developing specifc behavioural paradigms such as self-organisation \cite{SelfOrganizing} and path-formation \cite{PathFormation}, which give insight into the kinds of information and data that swarm robots use to make decisions, and that a swarm researcher might therefore be interested in monitoring. Beni \cite{FromSIToSR} presents a relatively informal but useful overview of the terminology used in the field, which may serve as useful additional reading to Sahin's overview.

The book `\textit{Swarm Intelligence: From Natural to Artificial Systems}' written by Bonabeau, Dorigo and Theraulaz \cite{Bonabeau:1999} provides in its introductory chapter a good overview of the biological concepts and animal behaviours which inspire the field of swarm intelligence. The later chapters provide a detailed look at several of these behaviours, and how mathematical models and algorithms can be derived from them. Although more detailed than this project requires, an understanding of these behaviours and models can offer insight into what information the application might need to expose to the user to allow them to validate the correct operation of a system based on these concepts.

%----------------------------------------------------------------------------------------

\section{Human Swarm Interaction} \label{HumanSwarmInteraction}
In their paper `\textit{Human Interaction with Robot Swarms: A Survey}' \cite{Kolling:2016} Kolling at el. begin by noting the lack of research into methods for interfacing humans and robot swarms. They suggest that real-world applications for swarm robotics systems are now within reach, and that discovering effective methods for allowing humans to control and/or supervise swarms is a key barrier to realising these systems. The paper \cite{Kolling:2016} provides a detailed analysis of human swarm interaction from a number of different perspectives. Of relevance to this project is the statement on page 15 that ``\textit{Proper supervision of a semiautonomous swarm requires the human operator to be able to observe the state and motion of the swarm, as well as predict its future state to within some reasonable accuracy}'' \cite{Kolling:2016}. Considering that swarm supervision and swarm debugging are highly comparable tasks - both involve observing the swarm whilst performing its task and determining the validity of the behaviour observed  - this statement lends credence to the aims of this project. The proposed application would allow the state of the swarm, including the internal state of individual robots, to be observed simultaneously with the physical positions and motions of the robots within their environment. The paper \cite{Kolling:2016} goes on to suggest that by observing the swarm over time the human operator will be able to provide `\textit{appropriate control inputs}'. In the case of this application, rather than providing control input, the human operator will be seeking to identify faults, and provide appropriate corrections to the system, however the concept of state visualisation remains relevant.

Rule and Forlizzi \cite{Rule:2012} present a thorough examination of the complexities of human robot interaction (HRI) when dealing with multi-robot (and multi-user) systems. Much of the paper focusses on control methods, which are not directly applicable to this project, however Section 2.4 titled \textit{Salience of Information} discusses the task of designing interfaces for displaying information about multi-robot systems to a human operator in a manner which is both information dense and rapidly understandable. The authors note that the use of colour has been shown to improve interface readability \cite{Christ:1984}, and that the brain has been shown to process text faster than images \cite{Carney:1998}, hence complex icons should be avoided. These ideas should be incorporated into the design of the application user interface for this project. A range of different designs could be explored, including finding a balance between the amount of information displayed graphically, and the amount displayed textually, and deciding whether to use colour to differentiate between individual robots, or to differentiate between different types of data, or a combination of both.

%----------------------------------------------------------------------------------------

\section{Debugging Robotics} \label{RoboticsDebugging}
Collet and MacDonald \cite{Collet:2006} describe in detail the difficulties in debugging robotics systems. The authors identify that the difficulties in developing and debugging robotics applications when compared to traditional software arise from either the environment of the robot - which will often be ``\textit{uncontrolled}'' and ``\textit{dynamic}'' - or from the mobile nature of the robot. Because the environment a given robot operates in is a real world space, the level of control that can be exerted over it by the researcher or operator is inherently limited \cite{Collet:2006}. The environment may therefore change over time, exhibit imperfections, and include other time-varying elements. A robot is a physical actor and will likely experience dynamic change in its sensor readings and its relationship to the environment over time. This is especially true for mobile robots, whose position and orientation will change over time. The behaviour of the robot often largely depends on these highly variable factors, and therefore replicating a given behaviour exactly becomes almost impossible. The authors go on to state that difficulties in debugging often arise from ``\textit{the programmer's lack of understanding of the robot's world view} \cite{Collet:2006}''. It can therefore be extrapolated that for a multi robot system such as a robot swarm this problem would be exacerbated. Each robot will have its own perception of the environment, which will differ based on differences in the robots positions and orientations as well as variations in the instrumentation of each robot. For a multi-robot system the programmer is required to have an understanding of not just one but multiple world views, adding yet more potential for error and inaccuracy, and further obscuring bugs or behavioural issues that the programmer is trying to diagnose. This paper \cite{Collet:2006} and further analysis of the problem in the swarm context suggest that developers working on these systems will need specific tools which mitigate these issues in order to develop effectively for swarm robotic platforms. This need forms the mandate for this project. Collet and MacDonald \cite{Collet:2006} also present an augmented reality based software tool for this purpose, which is discussed in Section \ref{AugmentedReality}.

%----------------------------------------------------------------------------------------

\section{AR and Robotics} \label{AugmentedReality}
Augmented reality presents a powerful tool for use with robotics, and specifically for debugging robotics, as it allows information gathered by a robot about an environment to be superimposed onto that environment in a way which can be inherently understood by humans. Milgram et al. \cite{Milgram:1993} discuss the different communication formats used to interface between humans and robots, grouping them into ``\textit{continuous}'' and ``\textit{discrete}'' formats. For any communication involving a spatial or temporal component, the process of converting to and from a discrete format in order to transmit this information is an unnecessary burden. Both humans and robots use the continuous spatial dimensions, and humans have an inherent, instinctive understanding of physical things expressed in three dimensions. The authors therefore identify that \cite{Milgram:1993} augmented reality provides an excellent means of supporting the communication of spatial information. Their paper focuses on the combination of stereoscopic displays and computer generated graphics to allow for more intuitive control of robotic systems. In the case of this project the concept is reversed; robots reporting spatial information for validation by a user should do so in a format which is inherently continuous such as AR, rather than one that is discrete such as text-based numerical output. This should in theory reduce the time required for a human to process the information. The authors note that \cite{Milgram:1993} the ideal system utilises both discrete and continuous formats where appropriate to best communicate the required information, and is ergonomically designed to allow the user to make use of both easily and intuitively.

Like much of the literature surveyed, this paper \cite{Milgram:1993} is focused primarily on robot control, rather than observation and monitoring. In spite of this much of the content of the paper remains applicable. Since the paper was written, just over twenty five years ago, major advancements have been made in virtually every area mentioned, including the quality and precision of robotic systems, their cognitive, perceptive and decision making abilities, augmented reality technologies and robotic autonomy. Because of this, some of the contents of the paper have fallen out of date. Specifically, the assumption that robots lack the level of autonomy required to survey their environment and then form and execute a series of steps to carry out a relatively high level task, such as ``find and go to object Q''\cite{Milgram:1993}, is no longer necessarily true. A number of modern robots possess sufficient sensing capabilities, processing power and cognitive programming to perform such tasks based on high level commands. This does not however de-value the AR methods discussed within, and given the increased complexity and sensing capabilities of modern robots AR based methods of interaction actually show more potential than ever. The paper however makes no mention of the potential for an AR system to report data from a robot's sensors visually, which may be attributed to the technological limitations of the time rather than an oversight by the authors.

Collet and MacDonald \cite{Collet:2006} suggest that augmented reality tools can address and mitigate some of the robotics debugging issues discussed in section \ref{RoboticsDebugging} by superimposing graphical representations of the robot's understanding of the environment on top of a live view of the environment itself \cite{Collet:2006}. Hence the programmer is able to see how the robot has interpreted the environment, and identify inconsistencies. The authors describe the image of the real world environment as the ``\textit{ground truth}'' against which the robot's view can be compared and contrasted \cite{Collet:2006}. Figure \ref{fig:Sonar} shows a visual example of this technique, where the data received from the robot's sonar sensors is converted to spatially situated 3D shapes and superimposed over the live image, and can therefore be verified visually by the user.

\begin{figure}
	\begin{center}
	\includegraphics[scale=0.6]{Sonar.png}
	\decoRule
	\caption[Sonar data visualisation. Collet and MacDonald \cite{Collet:2006}]{Sonar sensor data visualisation in Collet and MacDonald's system \cite{Collet:2006}.}
	\label{fig:Sonar}
	\end{center}
\end{figure}

The application developed during this project closely follows this paradigm; allowing the user to identify bugs by comparing the robot's knowledge of its environment and its decision making factors (collectively referred to as its state) with a view of the environment, in real time. The application aims to apply this concept specifically to swarm robotics systems, and therefore must allow the user to compare the states of multiple robots with the environment simultaneously. From the perspective of each robot in the swarm, the other robots will form part of the environment, therefore the application must take this into account when displaying the information. Because of the large increase in information from a single-robot system to a multi-robot one, it becomes important that the application provide a way for the user to filter what information is displayed, allowing them to focus on the primary aspect under test. Filtering also allows the user to compare and contrast specific robots against one another by filtering out information related to other robots, or by displaying in more detail information related to the robots of interest.

\section{Similar Work} \label{SimilarWork}
Ghiringhelli et al. \cite{Ghiringhelli:2014} present a system for augmenting a video feed of an environment containing a number of robots with real time information obtained from each of the robots. This is similar in concept to the system described by Collet and MacDonald \cite{Collet:2006}, but is designed specifically to target a multi-robot system. The authors identify the ability to overlay spatial information exposed by the robots on to the video feed in real time, in the form of situated graphical representations, as the most important debugging feature of the system. Figure \ref{fig:SpatiallySituated} shows a spatially situated overlay of data exposed by robot thirty two, in the authors system \cite{Ghiringhelli:2014}. A viewer is able to immediately verify the validity of the robot's world view from this image by comparing the blue overlay to the image beneath. Each robot features a coloured LED blinking a unique coded pattern to enable tracking, and the system uses homography techniques to map between the robots' frame of reference and the camera's. The project proposed in this report intends to use a simpler approach, with position and orientation tracking achieved through the use of the AruCo \cite{Garrido:2014} marker-based tracking system, and a birds-eye view position for the camera to simplify mapping by effectively reducing the space to a 2D approximation.

\begin{figure}
	\begin{center}
	\includegraphics[scale=0.8]{SpatiallySituatedData.png}
	\decoRule
	\caption[Spatially situation data overlay. Garrido et al. \cite{Garrido:2014}]{Example of spatially situated data overlayed on a live image in \cite{Garrido:2014}.}
	\label{fig:SpatiallySituated}
	\end{center}
\end{figure}
